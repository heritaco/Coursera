{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-l3gabVzlB-"
      },
      "source": [
        "# Programming Assignment\n",
        "\n",
        "## Saving and loading models, with application to the EuroSat dataset\n",
        "\n",
        "### Instructions\n",
        "\n",
        "In this notebook, you will create a neural network that classifies land uses and land covers from satellite imagery. You will save your model using Tensorflow's callbacks and reload it later. You will also load in a pre-trained neural network classifier and compare performance with it.\n",
        "\n",
        "Some code cells are provided for you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line:\n",
        "\n",
        "`#### GRADED CELL ####`\n",
        "\n",
        "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtZFzBJTzlCC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-27 08:38:28.004666: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-27 08:38:28.334959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764254308.430329    2929 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764254308.463218    2929 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764254308.674836    2929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764254308.674876    2929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764254308.674878    2929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764254308.674880    2929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-27 08:38:28.699527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# If you would like to make further imports from tensorflow, add them here\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUYE18LozlCG"
      },
      "source": [
        "#### The EuroSAT dataset\n",
        "\n",
        "In this assignment, you will use the [EuroSAT dataset](https://github.com/phelber/EuroSAT). It consists of 27000 labelled Sentinel-2 satellite images of different land uses: residential, industrial, highway, river, forest, pasture, herbaceous vegetation, annual crop, permanent crop and sea/lake. For a reference, see the following papers:\n",
        "- Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.\n",
        "- Introducing EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification. Patrick Helber, Benjamin Bischke, Andreas Dengel. 2018 IEEE International Geoscience and Remote Sensing Symposium, 2018.\n",
        "\n",
        "Your goal is to construct a neural network that classifies a satellite image into one of these 10 classes, as well as applying some of the saving and loading techniques you have learned in the previous sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgcHEE-HzlCH"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset you will train your model on is a subset of the total data, with 4000 training images and 1000 testing images, with roughly equal numbers of each class.\n",
        "The train and test datasets required for this project can be downloaded from the following links:\n",
        "\n",
        "`x_train`: https://drive.google.com/open?id=1cUaIEd9-MLJHFGjLz5QziNvfBtYygplX\n",
        "\n",
        "`y_train`: https://drive.google.com/open?id=1hv24Ufiio9rBeSqgnNoM3dr5sVGwOmBy\n",
        "\n",
        "`x_test`: https://drive.google.com/open?id=1AH9lKHT5P2oQLz8SGMRPWs_M9wIM2ZRH\n",
        "\n",
        "`y_test`: https://drive.google.com/open?id=1i4_azocSDuU3TcDf3OSHO1vF0D5-xMU6\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-27 08:44:12--  https://zenodo.org/api/records/7711810/files-archive\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.75, 137.138.52.235, 188.185.43.153, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘weekly_data/files-archive’\n",
            "\n",
            "files-archive           [  <=>               ]   2.01G  1.56MB/s    in 35m 42s \n",
            "\n",
            "2025-11-27 09:19:59 (985 KB/s) - ‘weekly_data/files-archive’ saved [2160061446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create the new folder weekly_data and download the data from the link provided in the instructions\n",
        "!mkdir -p weekly_data\n",
        "!wget -P weekly_data/ https://zenodo.org/api/records/7711810/files-archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mv weekly_data/files-archive weekly_data/files-archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "zip_path = \"weekly_data/files-archive.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add the folder to gitignore\n",
        "!echo \"weekly_data/\" >> .gitignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: unzip: command not found\n"
          ]
        }
      ],
      "source": [
        "!unzip -l weekly_data/files-archive.zip | head -40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 2\n",
            "EuroSAT_MS.zip\n",
            "EuroSAT_RGB.zip\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"weekly_data/files-archive.zip\"  # or \"weekly_data/files-archive.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "    files = zf.namelist()\n",
        "    print(\"Number of entries:\", len(files))\n",
        "    for name in files[:40]:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "outer_zip = Path(\"weekly_data/files-archive.zip\")  # or .zip if you renamed it\n",
        "output_dir = Path(\"weekly_data\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(outer_zip, \"r\") as zf:\n",
        "    # Extract only the RGB version\n",
        "    zf.extract(\"EuroSAT_RGB.zip\", path=output_dir)\n",
        "    # If you also want MS:\n",
        "    # zf.extract(\"EuroSAT_MS.zip\", path=output_dir)\n",
        "\n",
        "print((output_dir / \"EuroSAT_RGB.zip\").exists())  # should be True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted to: weekly_data/EuroSAT_RGB\n"
          ]
        }
      ],
      "source": [
        "inner_zip = output_dir / \"EuroSAT_RGB.zip\"\n",
        "rgb_dir = output_dir / \"EuroSAT_RGB\"\n",
        "rgb_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(inner_zip, \"r\") as zf:\n",
        "    zf.extractall(rgb_dir)\n",
        "\n",
        "print(\"Extracted to:\", rgb_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access '/EuroSAT_RGB': No such file or directory\n",
            "weekly_data:\n",
            "total 2201888\n",
            "drwxr-xr-x 3 nvidia nvidia       4096 Nov 27 09:43 EuroSAT_RGB\n",
            "-rw-r--r-- 1 nvidia nvidia   94658721 Nov 27 09:43 EuroSAT_RGB.zip\n",
            "-rw-r--r-- 1 nvidia nvidia 2160061446 Nov 27 09:19 files-archive.zip\n",
            "\n",
            "weekly_data/EuroSAT_RGB:\n",
            "total 4\n",
            "drwxr-xr-x 12 nvidia nvidia 4096 Nov 27 09:43 EuroSAT_RGB\n",
            "\n",
            "weekly_data/EuroSAT_RGB/EuroSAT_RGB:\n",
            "total 1168\n",
            "drwxr-xr-x 2 nvidia nvidia 126976 Nov 27 09:43 AnnualCrop\n",
            "drwxr-xr-x 2 nvidia nvidia 118784 Nov 27 09:43 Forest\n",
            "drwxr-xr-x 2 nvidia nvidia 176128 Nov 27 09:43 HerbaceousVegetation\n",
            "drwxr-xr-x 2 nvidia nvidia  94208 Nov 27 09:43 Highway\n",
            "drwxr-xr-x 2 nvidia nvidia 110592 Nov 27 09:43 Industrial\n",
            "drwxr-xr-x 2 nvidia nvidia  69632 Nov 27 09:43 Pasture\n",
            "drwxr-xr-x 2 nvidia nvidia 131072 Nov 27 09:43 PermanentCrop\n",
            "drwxr-xr-x 2 nvidia nvidia 135168 Nov 27 09:43 Residential\n",
            "drwxr-xr-x 2 nvidia nvidia  81920 Nov 27 09:43 River\n",
            "drwxr-xr-x 2 nvidia nvidia 118784 Nov 27 09:43 SeaLake\n",
            "\n",
            "weekly_data/EuroSAT_RGB/EuroSAT_RGB/AnnualCrop:\n",
            "total 12108\n",
            "-rw-r--r-- 1 nvidia nvidia 2737 Nov 27 09:45 AnnualCrop_1.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 2871 Nov 27 09:45 AnnualCrop_10.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3333 Nov 27 09:45 AnnualCrop_100.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3474 Nov 27 09:45 AnnualCrop_1000.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3330 Nov 27 09:45 AnnualCrop_1001.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 2986 Nov 27 09:45 AnnualCrop_1002.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 2888 Nov 27 09:45 AnnualCrop_1003.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3290 Nov 27 09:45 AnnualCrop_1004.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3131 Nov 27 09:45 AnnualCrop_1005.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 2713 Nov 27 09:45 AnnualCrop_1006.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 2810 Nov 27 09:45 AnnualCrop_1007.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3351 Nov 27 09:45 AnnualCrop_1008.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3306 Nov 27 09:45 AnnualCrop_1009.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3338 Nov 27 09:45 AnnualCrop_101.jpg\n",
            "-rw-r--r-- 1 nvidia nvidia 3331 Nov 27 09:45 AnnualCrop_1010.jpg\n",
            "ls: write error: Broken pipe\n"
          ]
        }
      ],
      "source": [
        "# view all the new files in the folder\n",
        "!ls -lR weekly_data /EuroSAT_RGB | head -40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_eurosat_data(\n",
        "    data_root=\"weekly_data/EuroSAT_RGB/EuroSAT_RGB\",\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    fraction=0.05,      # 0.05 = use 5% of images; set to 1.0 for all\n",
        "    seed=1337,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns (x_train, y_train), (x_test, y_test) as NumPy arrays\n",
        "    built from the EuroSAT RGB directory structure.\n",
        "    \"\"\"\n",
        "\n",
        "    data_root = Path(data_root)\n",
        "\n",
        "    # 1) Build TF datasets from directory (80% train, 20% \"test\")\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_root,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=seed,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"int\",\n",
        "    )\n",
        "\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_root,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=seed,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"int\",\n",
        "    )\n",
        "\n",
        "    # 2) Optionally reduce to a fraction (e.g. 5%) of the images\n",
        "    if fraction is not None and fraction < 1.0:\n",
        "        # Estimate total number of examples from number of batches * batch_size\n",
        "        n_train_batches = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "        n_test_batches  = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "\n",
        "        n_train = n_train_batches * batch_size\n",
        "        n_test  = n_test_batches * batch_size\n",
        "\n",
        "        n_train_small = int(n_train * fraction)\n",
        "        n_test_small  = int(n_test * fraction)\n",
        "\n",
        "        train_ds = train_ds.unbatch().take(n_train_small).batch(batch_size)\n",
        "        test_ds  = test_ds.unbatch().take(n_test_small).batch(batch_size)\n",
        "\n",
        "    # 3) Convert tf.data.Dataset → NumPy arrays\n",
        "    def ds_to_numpy(ds):\n",
        "        xs, ys = [], []\n",
        "        for x_batch, y_batch in ds:\n",
        "            xs.append(x_batch.numpy())\n",
        "            ys.append(y_batch.numpy())\n",
        "        x = np.concatenate(xs, axis=0)\n",
        "        y = np.concatenate(ys, axis=0)\n",
        "        return x, y\n",
        "\n",
        "    x_train, y_train = ds_to_numpy(train_ds)\n",
        "    x_test, y_test   = ds_to_numpy(test_ds)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 27000 files belonging to 10 classes.\n",
            "Using 21600 files for training.\n",
            "Found 27000 files belonging to 10 classes.\n",
            "Using 5400 files for validation.\n",
            "(1080, 64, 64, 3) (1080,)\n",
            "(270, 64, 64, 3) (270,)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_eurosat_data()\n",
        "\n",
        "# scale pixels to [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "x_test  = x_test  / 255.0\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afGjcvB3zlCL"
      },
      "source": [
        "# Build the neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv0kHsBozlCM"
      },
      "source": [
        "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
        "\n",
        "* The model should use the input_shape in the function argument to set the input size in the first layer.\n",
        "* The first layer should be a Conv2D layer with 16 filters, a 3x3 kernel size, a ReLU activation function and 'SAME' padding. Name this layer 'conv_1'.\n",
        "* The second layer should also be a Conv2D layer with 8 filters, a 3x3 kernel size, a ReLU activation function and 'SAME' padding. Name this layer 'conv_2'.\n",
        "* The third layer should be a MaxPooling2D layer with a pooling window size of 8x8. Name this layer 'pool_1'.\n",
        "* The fourth layer should be a Flatten layer, named 'flatten'.\n",
        "* The fifth layer should be a Dense layer with 32 units, a ReLU activation. Name this layer 'dense_1'.\n",
        "* The sixth and final layer should be a Dense layer with 10 units and softmax activation. Name this layer 'dense_2'.\n",
        "\n",
        "In total, the network should have 6 layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H84-I9P5zlCN"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_new_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the\n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should also compile the model with the Adam optimiser, sparse categorical cross\n",
        "    entropy loss function, and a single accuracy metric.\n",
        "    \"\"\"\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # 1) Conv2D, 16 filters, 3x3, ReLU, SAME padding\n",
        "    model.add(Conv2D(\n",
        "            filters=16,\n",
        "            kernel_size=(3, 3),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            input_shape=input_shape,\n",
        "            name=\"conv_1\",\n",
        "        ))\n",
        "    \n",
        "    # 2) Conv2D, 8 filters, 3x3, ReLU, SAME padding\n",
        "    model.add(Conv2D(\n",
        "            filters=8,\n",
        "            kernel_size=(3, 3),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            name=\"conv_2\",\n",
        "        ))\n",
        "    \n",
        "    # 3) MaxPooling2D, 8x8\n",
        "    model.add(MaxPooling2D(pool_size=(8, 8), name=\"pool_1\"))\n",
        "    \n",
        "    # 4) Flatten\n",
        "    model.add(Flatten(name=\"flatten\"))\n",
        "    \n",
        "    # 5) Dense, 32 units, ReLU\n",
        "    model.add(Dense(32, activation=\"relu\", name=\"dense_1\"))\n",
        "    \n",
        "    # 6) Dense, 10 units, softmax\n",
        "    model.add(Dense(10, activation=\"softmax\", name=\"dense_2\"))\n",
        "\n",
        "    # Compile with Adam, sparse categorical crossentropy, accuracy\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    loss = 'sparse_categorical_crossentropy'\n",
        "    metrics = ['accuracy']\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics,\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx6dXvwOzlCQ"
      },
      "source": [
        "#### Compile and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5BHOQzT5zlCR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_1 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_2 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m1,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m16,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,354</span> (71.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,354\u001b[0m (71.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,354</span> (71.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,354\u001b[0m (71.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run your function to create the model\n",
        "\n",
        "model = get_new_model(x_train[0].shape)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "--aE05n8zlCV"
      },
      "outputs": [],
      "source": [
        "# Run this cell to define a function to evaluate a model's test accuracy\n",
        "\n",
        "def get_test_accuracy(model, x_test, y_test):\n",
        "    \"\"\"Test model classification accuracy\"\"\"\n",
        "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test)\n",
        "    print('accuracy: {acc:0.3f}'.format(acc=test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4ezcwMrNzlCd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1259 - loss: 2.3065\n",
            "accuracy: 0.126\n"
          ]
        }
      ],
      "source": [
        "# Print the model summary and calculate its initialised test accuracy\n",
        "\n",
        "get_test_accuracy(model, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfIdxbQWzlCg"
      },
      "source": [
        "# Create checkpoints to save model during training, with a criterion\n",
        "\n",
        "You will now create three callbacks:\n",
        "- `checkpoint_every_epoch`: checkpoint that saves the model weights every epoch during training\n",
        "- `checkpoint_best_only`: checkpoint that saves only the weights with the highest validation accuracy. Use the testing data as the validation data.\n",
        "- `early_stopping`: early stopping object that ends training if the validation accuracy has not improved in 3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccQU2HMGzlCh"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following functions.\n",
        "# Make sure to not change the function names or arguments.\n",
        "\n",
        "def get_checkpoint_every_epoch():\n",
        "    \"\"\"\n",
        "    This function should return a ModelCheckpoint object that:\n",
        "    - saves the weights only at the end of every epoch\n",
        "    - saves into a directory called 'checkpoints_every_epoch' inside the current working directory\n",
        "    - generates filenames in that directory like 'checkpoint_XXX' where\n",
        "      XXX is the epoch number formatted to have three digits, e.g. 001, 002, 003, etc.\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(\"checkpoints_every_epoch\", \"checkpoint_{epoch:03d}\")\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        save_weights_only=True,\n",
        "        save_best_only=False,\n",
        "        save_freq=\"epoch\",\n",
        "        verbose=0,\n",
        "    )\n",
        "    return checkpoint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_checkpoint_best_only():\n",
        "    \"\"\"\n",
        "    This function should return a ModelCheckpoint object that:\n",
        "    - saves only the weights that generate the highest validation (testing) accuracy\n",
        "    - saves into a directory called 'checkpoints_best_only' inside the current working directory\n",
        "    - generates a file called 'checkpoints_best_only/checkpoint'\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(\"checkpoints_best_only\", \"checkpoint\")\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        save_weights_only=True,\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        verbose=0,\n",
        "    )\n",
        "    return checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RjYKmcXMzlCj"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_early_stopping():\n",
        "    \"\"\"\n",
        "    This function should return an EarlyStopping callback that stops training when\n",
        "    the validation (testing) accuracy has not improved in the last 3 epochs.\n",
        "    HINT: use the EarlyStopping callback with the correct 'monitor' and 'patience'\n",
        "    \"\"\"\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=3,\n",
        "        mode=\"max\",\n",
        "        verbose=0,\n",
        "    )\n",
        "    return early_stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jplngS9izlCn"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=checkpoints_every_epoch/checkpoint_{epoch:03d}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run this cell to create the callbacks\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m checkpoint_every_epoch = \u001b[43mget_checkpoint_every_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m checkpoint_best_only = get_checkpoint_best_only()\n\u001b[32m      5\u001b[39m early_stopping = get_early_stopping()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mget_checkpoint_every_epoch\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03mThis function should return a ModelCheckpoint object that:\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m- saves the weights only at the end of every epoch\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33;03m  XXX is the epoch number formatted to have three digits, e.g. 001, 002, 003, etc.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m filepath = os.path.join(\u001b[33m\"\u001b[39m\u001b[33mcheckpoints_every_epoch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheckpoint_\u001b[39m\u001b[38;5;132;01m{epoch:03d}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m checkpoint = \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/rapids-25.10-cuda12/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:155\u001b[39m, in \u001b[36mModelCheckpoint.__init__\u001b[39m\u001b[34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filepath.endswith(\u001b[33m\"\u001b[39m\u001b[33m.weights.h5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    156\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(Keras weights format). Received: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.filepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m         )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    163\u001b[39m         \u001b[38;5;28mself\u001b[39m.filepath.endswith(ext) \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m     ):\n",
            "\u001b[31mValueError\u001b[39m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=checkpoints_every_epoch/checkpoint_{epoch:03d}"
          ]
        }
      ],
      "source": [
        "# Run this cell to create the callbacks\n",
        "\n",
        "checkpoint_every_epoch = get_checkpoint_every_epoch()\n",
        "checkpoint_best_only = get_checkpoint_best_only()\n",
        "early_stopping = get_early_stopping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8DdH7hdzlCp"
      },
      "source": [
        "# Train model using the callbacks\n",
        "\n",
        "Now, you will train the model using the three callbacks you created. If you created the callbacks correctly, three things should happen:\n",
        "- At the end of every epoch, the model weights are saved into a directory called `checkpoints_every_epoch`\n",
        "- At the end of every epoch, the model weights are saved into a directory called `checkpoints_best_only` **only** if those weights lead to the highest test accuracy\n",
        "- Training stops when the testing accuracy has not improved in three epochs.\n",
        "\n",
        "You should then have two directories:\n",
        "- A directory called `checkpoints_every_epoch` containing filenames that include `checkpoint_001`, `checkpoint_002`, etc with the `001`, `002` corresponding to the epoch\n",
        "- A directory called `checkpoints_best_only` containing filenames that include `checkpoint`, which contain only the weights leading to the highest testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG329dBszlCq"
      },
      "outputs": [],
      "source": [
        "# Train model using the callbacks you just created\n",
        "\n",
        "callbacks = [checkpoint_every_epoch, checkpoint_best_only, early_stopping]\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKEb0lQ9zlCt"
      },
      "source": [
        "# Create new instance of model and load on both sets of weights\n",
        "\n",
        "Now you will use the weights you just saved in a fresh model. You should create two functions, both of which take a freshly instantiated model instance:\n",
        "- `model_last_epoch` should contain the weights from the latest saved epoch\n",
        "- `model_best_epoch` should contain the weights from the saved epoch with the highest testing accuracy\n",
        "\n",
        "_Hint: use the_ `tf.train.latest_checkpoint` _function to get the filename of the latest saved checkpoint file. Check the docs_ [_here_](https://www.tensorflow.org/api_docs/python/tf/train/latest_checkpoint)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nokhxEntzlCu"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following functions.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model_last_epoch(model):\n",
        "    \"\"\"\n",
        "    This function should create a new instance of the CNN you created earlier,\n",
        "    load on the weights from the last training epoch, and return this model.\n",
        "    \"\"\"\n",
        "    # Directory where you saved \"checkpoint_001\", \"checkpoint_002\", ...\n",
        "    ckpt_dir = \"checkpoints_every_epoch\"\n",
        "\n",
        "    # Get the path of the latest checkpoint\n",
        "    latest_ckpt = tf.train.latest_checkpoint(ckpt_dir)\n",
        "\n",
        "    # Load weights into the provided model instance\n",
        "    model.load_weights(latest_ckpt)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def get_model_best_epoch(model):\n",
        "    \"\"\"\n",
        "    This function should create a new instance of the CNN you created earlier, load\n",
        "    on the weights leading to the highest validation accuracy, and return this model.\n",
        "    \"\"\"\n",
        "    # For the \"best only\" case, we saved all best weights under a fixed prefix\n",
        "    best_ckpt_path = os.path.join(\"checkpoints_best_only\", \"checkpoint\")\n",
        "\n",
        "    # Load weights into the provided model instance\n",
        "    model.load_weights(best_ckpt_path)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0BEAOZYzlCx"
      },
      "outputs": [],
      "source": [
        "# Run this cell to create two models: one with the weights from the last training\n",
        "# epoch, and one wiht the weights leading to the highest validation (testing) accuracy.\n",
        "# Verify that the second has a higher validation (testing) accuarcy.\n",
        "\n",
        "model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))\n",
        "model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))\n",
        "print('Model with last epoch weights:')\n",
        "get_test_accuracy(model_last_epoch, x_test, y_test)\n",
        "print('')\n",
        "print('Model with best epoch weights:')\n",
        "get_test_accuracy(model_best_epoch, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AESpayizlC1"
      },
      "source": [
        "# Load, from scratch, a model trained on the EuroSat dataset.\n",
        "\n",
        "In your workspace, you will find another model trained on the `EuroSAT` dataset in `.h5` format. This model is trained on a larger subset of the EuroSAT dataset and has a more complex architecture. The path to the model is `models/EuroSatNet.h5`. See how its testing accuracy compares to your model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiUKJYebzlC2"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following functions.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model_eurosatnet():\n",
        "    \"\"\"\n",
        "    This function should return the pretrained EuroSatNet.h5 model.\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.load_model(\"models/EuroSatNet.h5\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEzAQ3yRzlC6"
      },
      "outputs": [],
      "source": [
        "# Run this cell to print a summary of the EuroSatNet model, along with its validation accuracy.\n",
        "\n",
        "model_eurosatnet = get_model_eurosatnet()\n",
        "model_eurosatnet.summary()\n",
        "get_test_accuracy(model_eurosatnet, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9vIBFVWzlC-"
      },
      "source": [
        "Congratulations for completing this programming assignment! You're now ready to move on to the capstone project for this course."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "tensor-flow-2-1",
      "graded_item_id": "JaRY0",
      "launcher_item_id": "mJ8fg"
    },
    "kernelspec": {
      "display_name": "rapids-25.10-cuda12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
