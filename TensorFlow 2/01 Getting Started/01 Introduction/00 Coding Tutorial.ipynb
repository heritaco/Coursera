{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install TensorFlow 2.5+ with GPU support in RAPIDS conda environment\n",
        "\n",
        "[RAPIDS conda environment](https://docs.rapids.ai/install/?_gl=1*1i29zjb*_ga*OTAzODc1OTEzLjE3NjQwMDgwODY.*_ga_RKXFW6CM42*czE3NjQwMDgwODUkbzEkZzAkdDE3NjQwMDgwODUkajYwJGwwJGgw#wsl2)\n",
        "\n",
        "\n",
        "```bash\n",
        "conda activate rapids-25.10\n",
        "\n",
        "# 1) upgrade pip inside env\n",
        "python -m pip install --upgrade pip\n",
        "\n",
        "# 2a) GPU-capable TF (official path)\n",
        "pip install \"tensorflow[and-cuda]\"     # installs TF + matching CUDA/cuDNN wheels\n",
        "\n",
        "# 2b) if 3.13 wheel is missing on your platform, try the RC/nightly\n",
        "pip install tensorflow==2.20.0rc0      # or: pip install tf-nightly\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAm4T0gKoQp"
      },
      "source": [
        "# Introduction to TensorFlow 2\n",
        "\n",
        "## Coding tutorials\n",
        "#### [1. Hello TensorFlow!](#coding_tutorial_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0863r0BFKoQr"
      },
      "source": [
        "---\n",
        "<a id='coding_tutorial_1'></a>\n",
        "## Hello TensorFlow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xaahw5pKoQz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-26 20:39:59.787796: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-26 20:39:59.900133: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-26 20:40:02.598181: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R54pSSl0KoQw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.20.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check its version\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3xaahw5pKoQz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "\n",
            "MNIST dataset loaded.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1764211205.892403  379719 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1991 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-26 20:40:08.658122: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f977c015470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-11-26 20:40:08.658151: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
            "2025-11-26 20:40:08.670363: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-11-26 20:40:08.753574: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
            "2025-11-26 20:40:09.075595: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-11-26 20:40:09.169293: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  36/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.2345 - loss: 2.1931"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1764211209.905937  379820 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.4371\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.2632\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.2307\n",
            "Model trained successfully!\n"
          ]
        }
      ],
      "source": [
        "# Train a feedforward neural network for image classification\n",
        "print('Loading data...\\n')\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print('MNIST dataset loaded.\\n')\n",
        "\n",
        "x_train = x_train/255.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training model...\\n')\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=32)\n",
        "\n",
        "print('Model trained successfully!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rapids-25.10-cuda12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
