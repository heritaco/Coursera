{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install TensorFlow 2.5+ with GPU support in RAPIDS conda environment\n",
        "\n",
        "[RAPIDS conda environment](https://docs.rapids.ai/install/?_gl=1*1i29zjb*_ga*OTAzODc1OTEzLjE3NjQwMDgwODY.*_ga_RKXFW6CM42*czE3NjQwMDgwODUkbzEkZzAkdDE3NjQwMDgwODUkajYwJGwwJGgw#wsl2)\n",
        "\n",
        "\n",
        "```bash\n",
        "conda activate rapids-25.10\n",
        "\n",
        "# 1) upgrade pip inside env\n",
        "python -m pip install --upgrade pip\n",
        "\n",
        "# 2a) GPU-capable TF (official path)\n",
        "pip install \"tensorflow[and-cuda]\"     # installs TF + matching CUDA/cuDNN wheels\n",
        "\n",
        "# 2b) if 3.13 wheel is missing on your platform, try the RC/nightly\n",
        "pip install tensorflow==2.20.0rc0      # or: pip install tf-nightly\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ug-wCIQwKoQi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.20.0'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAm4T0gKoQp"
      },
      "source": [
        "# Introduction to TensorFlow 2\n",
        "\n",
        "## Coding tutorials\n",
        "#### [1. Hello TensorFlow!](#coding_tutorial_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0863r0BFKoQr"
      },
      "source": [
        "---\n",
        "<a id='coding_tutorial_1'></a>\n",
        "## Hello TensorFlow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3xaahw5pKoQz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "MNIST dataset loaded.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1764009738.883110    4193 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5561 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-24 12:42:20.055112: I external/local_xla/xla/service/service.cc:163] XLA service 0x7c98f8004730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-11-24 12:42:20.055153: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
            "2025-11-24 12:42:20.069330: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-11-24 12:42:20.149086: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
            "2025-11-24 12:42:20.583279: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-11-24 12:42:20.651419: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  56/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3214 - loss: 2.0435"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1764009741.468383    6546 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.4151\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2403\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.2060\n",
            "Model trained successfully!\n"
          ]
        }
      ],
      "source": [
        "# Train a feedforward neural network for image classification\n",
        "\n",
        "print('Loading data...\\n')\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print('MNIST dataset loaded.\\n')\n",
        "\n",
        "x_train = x_train/255.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training model...\\n')\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=32)\n",
        "\n",
        "print('Model trained successfully!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rapids-25.10-cuda12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
